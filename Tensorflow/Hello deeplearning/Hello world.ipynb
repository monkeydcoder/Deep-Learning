{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc7c596a",
   "metadata": {},
   "source": [
    "# Hello world "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3902e6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version :  2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version : \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f468f6db",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b22216",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = X_train/255 , X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7244ec1",
   "metadata": {},
   "source": [
    "# Build a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f699a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403264e",
   "metadata": {},
   "source": [
    "Sequential is useful for stacking layers where each layer has one input tensor and one output tensor. Layers are functions with a known mathematical structure that can be reused and have trainable variables. Most TensorFlow models are composed of layers. This model uses the Flatten, Dense, and Dropout layers.\n",
    "\n",
    "For each example, the model returns a vector of logits or log-odds scores, one for each class.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600a560",
   "metadata": {},
   "source": [
    "In summary, the Dense layer creates fully connected layers in a neural network, while the Dropout layer helps prevent overfitting by randomly dropping out neurons during training, encouraging the network to learn more robust features. Both layers are crucial components in building effective neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9792870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57221216, -0.18794934, -0.05675144, -0.0215777 ,  0.13259645,\n",
       "         0.21593043,  0.3895805 , -0.16447993,  0.12875153, -0.25866452]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model(x_train[:1]).numpy()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba35485",
   "metadata": {},
   "source": [
    "The tf.nn.softmax function converts these logits to probabilities for each class:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce8a2f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15906413, 0.07437694, 0.0848041 , 0.08784006, 0.10248247,\n",
       "        0.11138868, 0.13251233, 0.07614317, 0.10208919, 0.06929902]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(prediction).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc03cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44097d9",
   "metadata": {},
   "source": [
    "In this line of code, you're defining a loss function for your model using TensorFlow's Keras API. Let's break it down:\n",
    "\n",
    "`tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)`\n",
    "\n",
    "- `tf.keras.losses`: This is the module in TensorFlow that provides various loss functions commonly used in machine learning tasks.\n",
    "\n",
    "- `SparseCategoricalCrossentropy`: This is the specific loss function being used. It is commonly used in classification tasks where the labels are integers (i.e., sparse targets), and the model outputs raw logits (i.e., unnormalized predictions) for each class.\n",
    "\n",
    "- `from_logits=True`: This parameter indicates that the model's output is not normalized, i.e., it's the output of the last layer before applying softmax activation. This means that the loss function will internally apply softmax to the model's output to compute probabilities before calculating the loss. If `from_logits` were `False`, it would expect the model's output to already be probabilities.\n",
    "\n",
    "Overall, `SparseCategoricalCrossentropy` loss function with `from_logits=True` is suitable when you're dealing with classification tasks where the model outputs logits and the labels are integers representing the class indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7b9af9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1947296"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], prediction).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc49daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48d115d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 658us/step - loss: 0.2919 - accuracy: 0.9148\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 661us/step - loss: 0.1426 - accuracy: 0.9576\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 684us/step - loss: 0.1078 - accuracy: 0.9673\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.0870 - accuracy: 0.9731\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 654us/step - loss: 0.0758 - accuracy: 0.9758\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.0660 - accuracy: 0.9788\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.0593 - accuracy: 0.9805\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 653us/step - loss: 0.0527 - accuracy: 0.9823\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 653us/step - loss: 0.0477 - accuracy: 0.9844\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 654us/step - loss: 0.0434 - accuracy: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17e3710d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ab0eb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0760 - accuracy: 0.9788 - 195ms/epoch - 623us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07603587955236435, 0.9787999987602234]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b7732e",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the TensorFlow tutorials.\n",
    "\n",
    "If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c27033b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c268602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[7.2208977e-08, 5.1359689e-10, 1.0222119e-06, 3.5545387e-04,\n",
       "        8.3594476e-13, 6.1339495e-10, 3.1637189e-18, 9.9964261e-01,\n",
       "        3.2343905e-08, 6.4239339e-07],\n",
       "       [6.5814482e-10, 3.6526501e-07, 9.9999964e-01, 8.9052801e-09,\n",
       "        1.9452352e-21, 3.2818310e-12, 7.5406278e-11, 9.4480208e-19,\n",
       "        2.4019285e-11, 8.5134172e-22],\n",
       "       [9.2007862e-10, 9.9968576e-01, 8.4192525e-06, 1.6895504e-07,\n",
       "        4.9494706e-06, 7.2912670e-08, 1.0919971e-06, 2.3207550e-04,\n",
       "        6.7374996e-05, 3.3978917e-10],\n",
       "       [9.9993765e-01, 1.7665510e-12, 5.9726994e-05, 1.7186187e-09,\n",
       "        2.9004694e-09, 1.6915941e-08, 2.8466926e-07, 1.9800829e-07,\n",
       "        2.2946398e-09, 2.1962142e-06],\n",
       "       [6.4903554e-09, 7.8881231e-14, 2.2413101e-08, 1.4121031e-11,\n",
       "        9.9988234e-01, 7.8005796e-11, 5.8829275e-09, 1.9136567e-06,\n",
       "        2.4136937e-10, 1.1571900e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf4c8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

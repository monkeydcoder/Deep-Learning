{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e1dafeb",
   "metadata": {},
   "source": [
    "# Rocks VS Mine using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127609ec",
   "metadata": {},
   "source": [
    "\n",
    "This is a dataset that describes sonar chirp returns bouncing off different services. The 60 input variables are the strength of the returns at different angles. It is a binary classification problem that requires a model to differentiate rocks from metal cylinders.\n",
    "\n",
    "Dataset information: https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks) Download it from here: https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "43b38192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9a2b1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Copy_of_sonar_ data.csv' , header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "99c7be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "03d0091c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "be3eb0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7d2e327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f3dad41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "395a1078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f0638aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "M    111\n",
       "R     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts() # Here values are not skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "700ffa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({60:{'R':0, 'M':1}}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8d792835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(60, axis=1)\n",
    "y = df[60]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c769e67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.2792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.1787</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "104  0.0307  0.0523  0.0653  0.0521  0.0611  0.0577  0.0665  0.0664  0.1460   \n",
       "146  0.1021  0.0830  0.0577  0.0627  0.0635  0.1328  0.0988  0.1787  0.1199   \n",
       "30   0.0240  0.0218  0.0324  0.0569  0.0330  0.0513  0.0897  0.0713  0.0569   \n",
       "19   0.0126  0.0149  0.0641  0.1732  0.2565  0.2559  0.2947  0.4110  0.4983   \n",
       "\n",
       "         9   ...      50      51      52      53      54      55      56  \\\n",
       "104  0.2792  ...  0.0063  0.0321  0.0189  0.0137  0.0277  0.0152  0.0052   \n",
       "146  0.1369  ...  0.1004  0.0709  0.0317  0.0309  0.0252  0.0087  0.0177   \n",
       "30   0.0389  ...  0.0061  0.0162  0.0146  0.0093  0.0112  0.0094  0.0054   \n",
       "19   0.5920  ...  0.0153  0.0092  0.0035  0.0098  0.0121  0.0006  0.0181   \n",
       "\n",
       "         57      58      59  \n",
       "104  0.0121  0.0124  0.0055  \n",
       "146  0.0214  0.0227  0.0106  \n",
       "30   0.0019  0.0066  0.0023  \n",
       "19   0.0094  0.0116  0.0063  \n",
       "\n",
       "[4 rows x 60 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9c58e7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 60)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2b544b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0aedfdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189    1\n",
       "170    1\n",
       "154    1\n",
       "30     0\n",
       "136    1\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f2754f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "1    111\n",
       "0     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7396a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f5a5c372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 60) (52, 60)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "79ddb049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 823us/step - loss: 0.7023 - accuracy: 0.5385\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 648us/step - loss: 0.6858 - accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 669us/step - loss: 0.6881 - accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 644us/step - loss: 0.6682 - accuracy: 0.6026\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 633us/step - loss: 0.6514 - accuracy: 0.6282\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 739us/step - loss: 0.6288 - accuracy: 0.6538\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 631us/step - loss: 0.6104 - accuracy: 0.7115\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 683us/step - loss: 0.5687 - accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 638us/step - loss: 0.5337 - accuracy: 0.7885\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 642us/step - loss: 0.5006 - accuracy: 0.8462\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 655us/step - loss: 0.4851 - accuracy: 0.8013\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 617us/step - loss: 0.4757 - accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 679us/step - loss: 0.4357 - accuracy: 0.8141\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 633us/step - loss: 0.4242 - accuracy: 0.8269\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 684us/step - loss: 0.3886 - accuracy: 0.8397\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 679us/step - loss: 0.3655 - accuracy: 0.8910\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 696us/step - loss: 0.3465 - accuracy: 0.8654\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 607us/step - loss: 0.3325 - accuracy: 0.8846\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 619us/step - loss: 0.3389 - accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 752us/step - loss: 0.3098 - accuracy: 0.8974\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 716us/step - loss: 0.2871 - accuracy: 0.8910\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 664us/step - loss: 0.2722 - accuracy: 0.9103\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 628us/step - loss: 0.2710 - accuracy: 0.8910\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 693us/step - loss: 0.2556 - accuracy: 0.9103\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 682us/step - loss: 0.2628 - accuracy: 0.8974\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 773us/step - loss: 0.2392 - accuracy: 0.9231\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 687us/step - loss: 0.2200 - accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 670us/step - loss: 0.1986 - accuracy: 0.9359\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 734us/step - loss: 0.1858 - accuracy: 0.9359\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 786us/step - loss: 0.1789 - accuracy: 0.9295\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 727us/step - loss: 0.1617 - accuracy: 0.9551\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 769us/step - loss: 0.1512 - accuracy: 0.9615\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 733us/step - loss: 0.1361 - accuracy: 0.9744\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 787us/step - loss: 0.1294 - accuracy: 0.9615\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 753us/step - loss: 0.1327 - accuracy: 0.9679\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 801us/step - loss: 0.1144 - accuracy: 0.9744\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 714us/step - loss: 0.1089 - accuracy: 0.9679\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 775us/step - loss: 0.1030 - accuracy: 0.9744\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 735us/step - loss: 0.1012 - accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 764us/step - loss: 0.0832 - accuracy: 0.9872\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 720us/step - loss: 0.0810 - accuracy: 0.9679\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 776us/step - loss: 0.0707 - accuracy: 0.9808\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 727us/step - loss: 0.0875 - accuracy: 0.9744\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 744us/step - loss: 0.0647 - accuracy: 0.9872\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 717us/step - loss: 0.0582 - accuracy: 0.9936\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 764us/step - loss: 0.0499 - accuracy: 0.9936\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 735us/step - loss: 0.0547 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 746us/step - loss: 0.0488 - accuracy: 0.9872\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 743us/step - loss: 0.0880 - accuracy: 0.9615\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 767us/step - loss: 0.0601 - accuracy: 0.9808\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 741us/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 816us/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 815us/step - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 782us/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 778us/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 857us/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 776us/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 851us/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 726us/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 824us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 717us/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 808us/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 725us/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 833us/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 710us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 826us/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 717us/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 826us/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 736us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 757us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 776us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 744us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 784us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 841us/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 932us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 845us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 943us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 947us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 932us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 850us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 982us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 872us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 925us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 937us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 866us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 910us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 724us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 758us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 721us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 743us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 709us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 754us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 709us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 739us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 717us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 752us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 717us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 741us/step - loss: 0.0024 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x291f3c950>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim = 60, activation = 'relu'),\n",
    "    keras.layers.Dense(30, activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy', \n",
    "    optimizer = 'adam', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4952f3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0422837734222412, 0.75]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1814a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebe90c9c",
   "metadata": {},
   "source": [
    "# As we can see the data is overfitted \n",
    "\n",
    "Training Accuracy >>> Test Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4045943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 735us/step - loss: 0.6792 - accuracy: 0.5705\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 765us/step - loss: 0.7390 - accuracy: 0.4359\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 691us/step - loss: 0.6770 - accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 659us/step - loss: 0.6951 - accuracy: 0.5256\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 718us/step - loss: 0.7111 - accuracy: 0.5128\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 665us/step - loss: 0.6834 - accuracy: 0.5705\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 716us/step - loss: 0.7088 - accuracy: 0.4744\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 651us/step - loss: 0.6770 - accuracy: 0.5962\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 693us/step - loss: 0.6860 - accuracy: 0.5641\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 666us/step - loss: 0.6797 - accuracy: 0.5962\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 689us/step - loss: 0.6891 - accuracy: 0.5064\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 662us/step - loss: 0.6849 - accuracy: 0.5897\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 655us/step - loss: 0.6668 - accuracy: 0.6026\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 710us/step - loss: 0.6576 - accuracy: 0.6346\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 676us/step - loss: 0.6832 - accuracy: 0.5705\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 835us/step - loss: 0.6745 - accuracy: 0.5385\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 664us/step - loss: 0.6604 - accuracy: 0.6154\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 715us/step - loss: 0.6373 - accuracy: 0.6410\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 656us/step - loss: 0.6389 - accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 718us/step - loss: 0.6174 - accuracy: 0.6859\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 646us/step - loss: 0.6102 - accuracy: 0.6090\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 698us/step - loss: 0.6315 - accuracy: 0.6474\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 664us/step - loss: 0.6161 - accuracy: 0.6795\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 673us/step - loss: 0.6161 - accuracy: 0.6154\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 760us/step - loss: 0.5555 - accuracy: 0.7308\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 774us/step - loss: 0.6012 - accuracy: 0.7051\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 742us/step - loss: 0.5657 - accuracy: 0.6859\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 770us/step - loss: 0.5703 - accuracy: 0.6538\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 762us/step - loss: 0.6136 - accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 788us/step - loss: 0.5549 - accuracy: 0.7564\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 747us/step - loss: 0.5688 - accuracy: 0.7051\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 793us/step - loss: 0.5325 - accuracy: 0.7564\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 760us/step - loss: 0.5199 - accuracy: 0.7372\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 823us/step - loss: 0.5658 - accuracy: 0.7308\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 755us/step - loss: 0.5159 - accuracy: 0.7692\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 825us/step - loss: 0.4971 - accuracy: 0.7756\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 749us/step - loss: 0.4517 - accuracy: 0.8269\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 807us/step - loss: 0.4904 - accuracy: 0.8141\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 739us/step - loss: 0.4619 - accuracy: 0.7949\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 835us/step - loss: 0.4875 - accuracy: 0.7885\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 744us/step - loss: 0.4945 - accuracy: 0.7756\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 825us/step - loss: 0.4622 - accuracy: 0.8141\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 748us/step - loss: 0.4592 - accuracy: 0.7885\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 825us/step - loss: 0.4531 - accuracy: 0.7821\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 741us/step - loss: 0.4409 - accuracy: 0.8141\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 853us/step - loss: 0.4290 - accuracy: 0.8013\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 723us/step - loss: 0.4479 - accuracy: 0.7949\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 735us/step - loss: 0.4431 - accuracy: 0.8013\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 779us/step - loss: 0.3874 - accuracy: 0.8141\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.8205\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8269\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 943us/step - loss: 0.3818 - accuracy: 0.8397\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4012 - accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.8141\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 904us/step - loss: 0.3745 - accuracy: 0.8526\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 943us/step - loss: 0.3605 - accuracy: 0.8590\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 930us/step - loss: 0.4386 - accuracy: 0.8077\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 895us/step - loss: 0.3876 - accuracy: 0.8654\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8462\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 959us/step - loss: 0.3940 - accuracy: 0.8462\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.8462\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8846\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8462\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 907us/step - loss: 0.3306 - accuracy: 0.8846\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 969us/step - loss: 0.3896 - accuracy: 0.8462\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 922us/step - loss: 0.4316 - accuracy: 0.8141\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 930us/step - loss: 0.3037 - accuracy: 0.8846\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 965us/step - loss: 0.3248 - accuracy: 0.8654\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 902us/step - loss: 0.2955 - accuracy: 0.8846\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 967us/step - loss: 0.3467 - accuracy: 0.8654\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 979us/step - loss: 0.3608 - accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 895us/step - loss: 0.2737 - accuracy: 0.8782\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8462\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 940us/step - loss: 0.2765 - accuracy: 0.9103\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 915us/step - loss: 0.3082 - accuracy: 0.8974\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 978us/step - loss: 0.3056 - accuracy: 0.8910\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 907us/step - loss: 0.2991 - accuracy: 0.9038\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 982us/step - loss: 0.3147 - accuracy: 0.8590\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 957us/step - loss: 0.3133 - accuracy: 0.9038\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 883us/step - loss: 0.2513 - accuracy: 0.9167\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 997us/step - loss: 0.2757 - accuracy: 0.8910\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 932us/step - loss: 0.2921 - accuracy: 0.8846\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 899us/step - loss: 0.3421 - accuracy: 0.8205\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 904us/step - loss: 0.3115 - accuracy: 0.8782\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 764us/step - loss: 0.2897 - accuracy: 0.8910\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 829us/step - loss: 0.3153 - accuracy: 0.8782\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 748us/step - loss: 0.2913 - accuracy: 0.9103\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 841us/step - loss: 0.2576 - accuracy: 0.8974\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 752us/step - loss: 0.2401 - accuracy: 0.9231\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 836us/step - loss: 0.2483 - accuracy: 0.9103\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 745us/step - loss: 0.2328 - accuracy: 0.9038\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 761us/step - loss: 0.2373 - accuracy: 0.9038\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 757us/step - loss: 0.2252 - accuracy: 0.9103\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 769us/step - loss: 0.2464 - accuracy: 0.9167\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 764us/step - loss: 0.2554 - accuracy: 0.9167\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 787us/step - loss: 0.3153 - accuracy: 0.8654\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 749us/step - loss: 0.3455 - accuracy: 0.8269\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 773us/step - loss: 0.2471 - accuracy: 0.8974\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 776us/step - loss: 0.2621 - accuracy: 0.9103\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 760us/step - loss: 0.2791 - accuracy: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29288ddd0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim = 60, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(30, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy', \n",
    "    optimizer = 'adam', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "551b89d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46716398000717163, 0.807692289352417]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1807e42d",
   "metadata": {},
   "source": [
    "# As we can see the Accuracy is been increased from 75% to 80 % \n",
    "\n",
    "\n",
    "By using the Dropout layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3e718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
